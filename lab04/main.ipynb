{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "from timeit import default_timer\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "OUT_DIR = 'out'\n",
    "if not os.path.exists(OUT_DIR):\n",
    "    os.makedirs(OUT_DIR)\n",
    "\n",
    "def savefig(fname):\n",
    "    plt.savefig(f'{OUT_DIR}/{fname}')\n",
    "    plt.savefig(f'{OUT_DIR}/{fname}.svg')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import calinski_harabasz_score, davies_bouldin_score\n",
    "\n",
    "def plot_elbow(data, out_fname, n_clusters, n_rounds=10, n_init=10):\n",
    "\n",
    "    score1 = []\n",
    "    score2 = []\n",
    "    times = []\n",
    "\n",
    "    for cl in tqdm(range(2, n_clusters + 1)):\n",
    "        t0 = default_timer()\n",
    "        score1_ = []\n",
    "        score2_ = []\n",
    "\n",
    "        for _ in range(n_rounds):\n",
    "            kmeans = KMeans(n_clusters=cl, n_init=n_init)\n",
    "            kmeans.fit(data)\n",
    "            score1_.append(calinski_harabasz_score(data, kmeans.labels_))\n",
    "            score2_.append(davies_bouldin_score(data, kmeans.labels_))\n",
    "        score1.append(np.mean(score1_))\n",
    "        score2.append(np.mean(score2_))\n",
    "        t1 = default_timer()\n",
    "        elapsed = t1 - t0\n",
    "        times.append(elapsed / n_rounds)\n",
    "\n",
    "    plt.plot(np.arange(2, n_clusters + 1), score1, marker='o')\n",
    "    plt.title('Calinski-Harabasz Index (higher is better)')\n",
    "    plt.xlabel('cluster amount')\n",
    "    plt.ylabel('index value')\n",
    "    savefig(f'elbow_chart_1_{out_fname}')\n",
    "\n",
    "    plt.plot(np.arange(2, n_clusters + 1), score2, marker='o')\n",
    "    plt.title('Davies-Bouldin Index (lower is better)')\n",
    "    plt.xlabel('cluster amount')\n",
    "    plt.ylabel('index value')\n",
    "    savefig(f'elbow_chart_2_{out_fname}')\n",
    "\n",
    "    plt.plot(np.arange(2, n_clusters + 1), times, marker='o')\n",
    "    plt.xlabel('cluster amount')\n",
    "    plt.ylabel('computation time [s]')\n",
    "    savefig(f'elbow_times_{out_fname}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Dummy data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def read_2d_input(filename):\n",
    "    img = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
    "    xx, yy = np.meshgrid(np.arange(img.shape[1]), np.flip(np.arange(img.shape[0])))\n",
    "    table = np.vstack([img.ravel(), xx.ravel(), yy.ravel()]).T\n",
    "    return np.array([(x, y) for c, x, y in table if c == 0])\n",
    "\n",
    "\n",
    "data_simple = read_2d_input('data_simple.png')\n",
    "plt.scatter(*data_simple.T)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Dummy data clustering"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_elbow(data_simple, 'simple', 20);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2)\n",
    "fig.tight_layout()\n",
    "for i in range(4):\n",
    "    cl = 10 + i\n",
    "    kmeans = KMeans(n_clusters=cl, n_init=10)\n",
    "    kmeans.fit(data_simple)\n",
    "    cluster_labels = kmeans.labels_\n",
    "    ax0 = ax[i // 2, i % 2]\n",
    "    ax0.set_title(f'n_clusters = {cl}')\n",
    "    ax0.set_xticks([], [])\n",
    "    ax0.set_yticks([], [])\n",
    "    ax0.scatter(*data_simple.T, c=cluster_labels, cmap='Paired', s=5)\n",
    "    ax0.scatter(*kmeans.cluster_centers_.T, marker='h', c='black', s=30)\n",
    "savefig('clusters_dummy_data')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "data = pd.read_csv('players_22.csv')\n",
    "\n",
    "data_cleaned = data.select_dtypes(include=['int16', 'int32', 'int64', 'float16', 'float32', 'float64'])\n",
    "data_cleaned = SimpleImputer(missing_values=np.nan, strategy='mean').fit_transform(data_cleaned)\n",
    "data_cleaned = StandardScaler().fit_transform(data_cleaned)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_elbow(data_cleaned, '', 30);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "\n",
    "def find_centers(model):\n",
    "    X = pd.DataFrame(data_cleaned)\n",
    "    min_dist = np.min(cdist(X, model.cluster_centers_, 'euclidean'), axis=1, )\n",
    "    Y = pd.DataFrame(min_dist, index=X.index, columns=['Centered_euclidean_dist'])\n",
    "    Z = pd.DataFrame(model.labels_, index=X.index, columns=['cluster_ID'])\n",
    "    PAP = pd.concat([Y, Z], axis=1)\n",
    "    idxs = np.array(PAP.groupby(['cluster_ID']).idxmin().values.tolist()).squeeze()\n",
    "    names = [data['long_name'][i] for i in idxs]\n",
    "    return names"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def clusters_overall(labels, fname):\n",
    "    df = pd.DataFrame(data)\n",
    "    clusters = df.groupby(labels)\n",
    "    overall = clusters['overall'].describe()\n",
    "    overall = overall.round(2)\n",
    "    overall = overall.astype({'count': 'int32'})\n",
    "    overall.to_csv(f'{OUT_DIR}/{fname}.csv', index_label='cluster')\n",
    "    return overall"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kmeans = KMeans(11, n_init=100)\n",
    "kmeans.fit(data_cleaned)\n",
    "\n",
    "print(find_centers(kmeans))\n",
    "print(clusters_overall(kmeans.labels_, 'overall_1'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Adaptive clustering"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "\n",
    "def adaptive_clustering(data, n_init=10, min_cluster_size=5, alpha=0.05):\n",
    "    data_labels = ['-2137' for _ in range(len(data))]\n",
    "\n",
    "    def _adaptive_clustering(cluster, indexes, label_prefix):\n",
    "        if len(cluster) < min_cluster_size:\n",
    "            for idx in indexes:\n",
    "                data_labels[idx] = f'{label_prefix}0'\n",
    "            return\n",
    "\n",
    "        kmeans = KMeans(n_clusters=2, n_init=n_init)\n",
    "        kmeans.fit(cluster)\n",
    "\n",
    "        p1, p2 = kmeans.cluster_centers_[0], kmeans.cluster_centers_[1]\n",
    "        l2 = np.sum((p1 - p2) ** 2)\n",
    "        if l2 == 0:\n",
    "            return\n",
    "        line_projection = []\n",
    "        for p3 in cluster:\n",
    "            t = np.sum((p3 - p1) * (p2 - p1)) / l2\n",
    "            line_projection.append(p1 + t * (p2 - p1))\n",
    "\n",
    "        stat, p = shapiro(line_projection)\n",
    "        if p > alpha:\n",
    "            for idx, label in zip(indexes, kmeans.labels_):\n",
    "                data_labels[idx] = f'{label_prefix}{label}'\n",
    "        else:\n",
    "            cl1, cl2, idx1, idx2 = [], [], [], []\n",
    "            for idx, sample, label in zip(indexes, cluster, kmeans.labels_):\n",
    "                if label == 0:\n",
    "                    idx1.append(idx)\n",
    "                    cl1.append(sample)\n",
    "                else:\n",
    "                    idx2.append(idx)\n",
    "                    cl2.append(sample)\n",
    "            _adaptive_clustering(cl1, idx1, f'{label_prefix}0')\n",
    "            _adaptive_clustering(cl2, idx2, f'{label_prefix}1')\n",
    "\n",
    "    _adaptive_clustering(data, np.arange(len(data)), '')\n",
    "\n",
    "    label_dict = dict()\n",
    "    new_label = 0\n",
    "    for label in data_labels:\n",
    "        if label not in label_dict:\n",
    "            label_dict[label] = new_label\n",
    "            new_label += 1\n",
    "\n",
    "    labels = [label_dict[data_labels[idx]] for idx in range(len(data))]\n",
    "\n",
    "    return labels\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "min_cluster_size = 55\n",
    "alpha=1e-7\n",
    "labels = adaptive_clustering(data_simple, min_cluster_size=min_cluster_size, alpha=alpha)\n",
    "print(len(np.unique(labels)))\n",
    "plt.scatter(*data_simple.T, c=labels, cmap='Paired')\n",
    "plt.title(f'min_cluster_size={min_cluster_size}, alpha={alpha}')\n",
    "savefig('adaptive_clustering')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels = adaptive_clustering(data_cleaned, n_init=100, min_cluster_size=1000, alpha=1e-7)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(clusters_overall(labels, 'overall_2'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "score1 = calinski_harabasz_score(data_cleaned, kmeans.labels_)\n",
    "score2 = davies_bouldin_score(data_cleaned, kmeans.labels_)\n",
    "print(f'{score1:.2f}')\n",
    "print(f'{score2:.2f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}